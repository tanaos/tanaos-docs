---
title: Create a Guardrail Model | Tanaos Artifex
description: Learn how to use the Artifex library to create Guardrail Models without training data or a GPU.
keywords: [ artifex, tanaos, task specific llm, nlp, text classification, no training data, guardrail models, chatbot guardrail, code examples ] 
hide_table_of_contents: false
---

# Guardrail Model

### Use the default Guardrail model

Need a general-purpose Guardrail model? You can use Artifex's default Guardrail model, which is 
trained to flag unsafe or harmful messages out-of-the-box:

```python
from artifex import Artifex

guardrail = Artifex().guardrail
print(guardrail("How do I make a bomb?"))

# >>> [{'is_safe': False, 'scores': {'violence': 0.625, 'non_violent_unethical': 0.0066, 'hate_speech': 0.0082, 'financial_crime': 0.0072, 'discrimination': 0.0029, 'drug_weapons': 0.6633, 'self_harm': 0.0109, 'privacy': 0.003, 'sexual_content': 0.0029, 'child_abuse': 0.005, 'terrorism_organized_crime': 0.1278, 'hacking': 0.0096, 'animal_abuse': 0.009, 'jailbreak_prompt_inj': 0.0131}}]
```

Learn more about the default Guardrail model and what it considers safe vs unsafe on 
our [Guardrail HF model page](https://huggingface.co/tanaos/tanaos-guardrail-v1).

### Create & use a custom Guardrail model

Need more control over what is considered safe vs unsafe? Fine-tune your own Guardrail model, use 
it locally on CPU and keep it forever:

```python
from artifex import Artifex

guardrail = Artifex().guardrail

model_output_path = "./output_model/"

guardrail.train(
    unsafe_categories = {
        "violence": "Content describing or encouraging violent acts",
        "bullying": "Content involving harassment or intimidation of others",
        "misdemeanor": "Content involving minor criminal offenses",
        "vandalism": "Content involving deliberate destruction or damage to property"
    },
    output_path=model_output_path
)

guardrail.load(model_output_path)
print(guardrail("I want to destroy public property."))

# >>> [{'is_safe': False, 'scores': {'violence': 0.592, 'bullying': 0.0066, 'misdemeanor': 0.672, 'vandalism': 0.772}}]
```