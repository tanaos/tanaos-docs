---
title: Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex
description: Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.
keywords: [ artifex, tanaos, python, library, task specific llm, nlp, text classification, no training data, observability ]
id: intro
hide_table_of_contents: false
---

import Link from '@docusaurus/Link';

import { PLATFORM_BASE_URL, PLATFORM_API_KEY_URL, PLATFORM_TRACES_PAGE } from '../../consts';


# Monitoring, Evaluation & Observability

Artifex includes built-in tools to **automatically monitor and evaluate** the inference and 
training performance of your models over time. This logging is performed **entirely on your 
machine**. Monitoring and logging are crucial to ensure your models are performing as expected and 
to identify any potential issues early on. All logs are written automatically after every 
inference and training session in the `artifex_logs/` folder in your current working directory. 

Logs include **operation-level metrics** (e.g., inference duration, CPU & RAM usage, training 
loss, etc.), **daily aggregated metrics** and any **errors encountered** during inference or 
training. Additionally, **warnings for potential issues** (e.g., high inference duration, low 
confidence scores, high training loss, etc.) are logged in a separate warnings log file for easier 
identification and troubleshooting.

Below is a list of all the metrics and warnings logged by Artifex:

## Inference logs:

- timestamp
- model used
- inference duration
- CPU & RAM usage
- input token count
- inference input & output
- inference errors (if any)
- Daily total inferences count
- Daily total & average input token count
- Daily total & average inference duration
- Daily average RAM & CPU usage
- Daily average confidence score
- Daily model usage breakdown

## Training logs:

- timestamp
- model trained
- training duration
- CPU & RAM usage
- training instructions & parameters
- training results (loss, samples/second, steps/second)
- training errors (if any)
- Daily total trainings count
- Daily average training duration
- Daily average CPU & RAM usage

## Warning logs:

- Warning for low confidence scores during inference
- Warning for slow inference (> 5 seconds)
- Warning for high inference input token count (> 2048 tokens)
- Warning for short inference input text (< 10 characters)
- Warning for null inference output
- Warning for high training loss (> 1.0)
- Warning for slow training (> 5 minutes)
- Warning for low training throughput (< 1 sample/second)

## Centralized logging, monitoring and alerting

Want to view, search, and correlate logs from all your models in one place, to easily debug production issues and understand system behavior over time, without digging through individual log files? Simply do the following:
1. Create a free account <Link to={PLATFORM_BASE_URL}>on the Tanaos platform</Link>
2. Create an API key from <Link to={PLATFORM_API_KEY_URL}>your profile page</Link>
3. Instantiate Artifex with your API key:

    ```python
    from artifex import Artifex

    guardrail = Artifex(
        api_key="<YOUR_API_KEY_HERE>"
    ).guardrail
    ```
4. Use Artifex as usual. All logs will be sent to your account on our platform. You can view them 
on <Link to={PLATFORM_TRACES_PAGE}>your traces page</Link>.

<img src="https://raw.githubusercontent.com/tanaos/artifex/master/assets/platform-inference-logs.png" width="600px" alt="Artifex â€“ Centralized logging, monitoring and alerting for Small Language Models" />


## Opting out of logging

You can opt-out of logging by passing the `disable_logging=True` flag when training or performing 
inference with any model:

```python
from artifex import Artifex

guardrail = Artifex().guardrail
print(guardrail("How do I make a bomb?", disable_logging=True))
```