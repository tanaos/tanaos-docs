"use strict";(self.webpackChunksynthex_docs=self.webpackChunksynthex_docs||[]).push([[2870],{7043:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>s,contentTitle:()=>l,default:()=>g,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"monitoring-evaluation-observability/intro","title":"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex","description":"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.","source":"@site/docs-artifex/monitoring-evaluation-observability/intro.mdx","sourceDirName":"monitoring-evaluation-observability","slug":"/monitoring-evaluation-observability/intro","permalink":"/artifex/monitoring-evaluation-observability/intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex","description":"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.","keywords":["artifex","tanaos","python","library","task specific llm","nlp","text classification","no training data","observability"],"id":"intro","hide_table_of_contents":false},"sidebar":"sidebar","previous":{"title":"Code Examples","permalink":"/artifex/topic-classification/code-examples"}}');var t=e(4848),a=e(8453);const o={title:"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex",description:"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.",keywords:["artifex","tanaos","python","library","task specific llm","nlp","text classification","no training data","observability"],id:"intro",hide_table_of_contents:!1},l="Monitoring, Evaluation & Observability",s={},c=[{value:"Inference logs:",id:"inference-logs",level:2},{value:"Training logs:",id:"training-logs",level:2},{value:"Warning logs:",id:"warning-logs",level:2},{value:"Opting out of logging",id:"opting-out-of-logging",level:2}];function d(n){const i={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"monitoring-evaluation--observability",children:"Monitoring, Evaluation & Observability"})}),"\n",(0,t.jsxs)(i.p,{children:["Artifex includes built-in tools to ",(0,t.jsx)(i.strong,{children:"automatically monitor and evaluate"})," the inference and\ntraining performance of your models over time. This logging is performed ",(0,t.jsx)(i.strong,{children:"entirely on your\nmachine"}),". Monitoring and logging are crucial to ensure your models are performing as expected and\nto identify any potential issues early on. All logs are written automatically after every\ninference and training session in the ",(0,t.jsx)(i.code,{children:"artifex_logs/"})," folder in your current working directory."]}),"\n",(0,t.jsxs)(i.p,{children:["Logs include ",(0,t.jsx)(i.strong,{children:"operation-level metrics"})," (e.g., inference duration, CPU & RAM usage, training\nloss, etc.), ",(0,t.jsx)(i.strong,{children:"daily aggregated metrics"})," and any ",(0,t.jsx)(i.strong,{children:"errors encountered"})," during inference or\ntraining. Additionally, ",(0,t.jsx)(i.strong,{children:"warnings for potential issues"})," (e.g., high inference duration, low\nconfidence scores, high training loss, etc.) are logged in a separate warnings log file for easier\nidentification and troubleshooting."]}),"\n",(0,t.jsx)(i.p,{children:"Below is a list of all the metrics and warnings logged by Artifex:"}),"\n",(0,t.jsx)(i.h2,{id:"inference-logs",children:"Inference logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"timestamp"}),"\n",(0,t.jsx)(i.li,{children:"model used"}),"\n",(0,t.jsx)(i.li,{children:"inference duration"}),"\n",(0,t.jsx)(i.li,{children:"CPU & RAM usage"}),"\n",(0,t.jsx)(i.li,{children:"input token count"}),"\n",(0,t.jsx)(i.li,{children:"inference input & output"}),"\n",(0,t.jsx)(i.li,{children:"inference errors (if any)"}),"\n",(0,t.jsx)(i.li,{children:"Daily total inferences count"}),"\n",(0,t.jsx)(i.li,{children:"Daily total & average input token count"}),"\n",(0,t.jsx)(i.li,{children:"Daily total & average inference duration"}),"\n",(0,t.jsx)(i.li,{children:"Daily average RAM & CPU usage"}),"\n",(0,t.jsx)(i.li,{children:"Daily average confidence score"}),"\n",(0,t.jsx)(i.li,{children:"Daily model usage breakdown"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"training-logs",children:"Training logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"timestamp"}),"\n",(0,t.jsx)(i.li,{children:"model trained"}),"\n",(0,t.jsx)(i.li,{children:"training duration"}),"\n",(0,t.jsx)(i.li,{children:"CPU & RAM usage"}),"\n",(0,t.jsx)(i.li,{children:"training instructions & parameters"}),"\n",(0,t.jsx)(i.li,{children:"training results (loss, samples/second, steps/second)"}),"\n",(0,t.jsx)(i.li,{children:"training errors (if any)"}),"\n",(0,t.jsx)(i.li,{children:"Daily total trainings count"}),"\n",(0,t.jsx)(i.li,{children:"Daily average training duration"}),"\n",(0,t.jsx)(i.li,{children:"Daily average CPU & RAM usage"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"warning-logs",children:"Warning logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Warning for low confidence scores during inference"}),"\n",(0,t.jsx)(i.li,{children:"Warning for slow inference (> 5 seconds)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for high inference input token count (> 2048 tokens)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for short inference input text (< 10 characters)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for null inference output"}),"\n",(0,t.jsx)(i.li,{children:"Warning for high training loss (> 1.0)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for slow training (> 5 minutes)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for low training throughput (< 1 sample/second)"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"opting-out-of-logging",children:"Opting out of logging"}),"\n",(0,t.jsxs)(i.p,{children:["You can opt-out of logging by passing the ",(0,t.jsx)(i.code,{children:"disable_logging=True"})," flag when training or performing\ninference with any model:"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'from artifex import Artifex\n\nguardrail = Artifex().guardrail\nprint(guardrail("How do I make a bomb?", disable_logging=True))\n'})})]})}function g(n={}){const{wrapper:i}={...(0,a.R)(),...n.components};return i?(0,t.jsx)(i,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>o,x:()=>l});var r=e(6540);const t={},a=r.createContext(t);function o(n){const i=r.useContext(a);return r.useMemo((function(){return"function"==typeof n?n(i):{...i,...n}}),[i,n])}function l(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),r.createElement(a.Provider,{value:i},n.children)}}}]);