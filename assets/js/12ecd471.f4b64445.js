"use strict";(self.webpackChunksynthex_docs=self.webpackChunksynthex_docs||[]).push([[2870],{7043:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>g});const r=JSON.parse('{"id":"monitoring-evaluation-observability/intro","title":"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex","description":"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.","source":"@site/docs-artifex/monitoring-evaluation-observability/intro.mdx","sourceDirName":"monitoring-evaluation-observability","slug":"/monitoring-evaluation-observability/intro","permalink":"/artifex/monitoring-evaluation-observability/intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex","description":"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.","keywords":["artifex","tanaos","python","library","task specific llm","nlp","text classification","no training data","observability"],"id":"intro","hide_table_of_contents":false},"sidebar":"sidebar","previous":{"title":"Code Examples","permalink":"/artifex/topic-classification/code-examples"}}');var t=e(4848),o=e(8453),a=e(8774),l=e(8738);const s={title:"Monitoring, Evaluation & Observability for Small Language Models | Tanaos Artifex",description:"Monitor and evaluate task-specific Small Language Models created with Artifex, ensuring optimal performance and reliability in NLP applications.",keywords:["artifex","tanaos","python","library","task specific llm","nlp","text classification","no training data","observability"],id:"intro",hide_table_of_contents:!1},c="Monitoring, Evaluation & Observability",d={},g=[{value:"Inference logs:",id:"inference-logs",level:2},{value:"Training logs:",id:"training-logs",level:2},{value:"Warning logs:",id:"warning-logs",level:2},{value:"Centralized logging, monitoring and alerting",id:"centralized-logging-monitoring-and-alerting",level:2},{value:"Opting out of logging",id:"opting-out-of-logging",level:2}];function u(n){const i={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"monitoring-evaluation--observability",children:"Monitoring, Evaluation & Observability"})}),"\n",(0,t.jsxs)(i.p,{children:["Artifex includes built-in tools to ",(0,t.jsx)(i.strong,{children:"automatically monitor and evaluate"})," the inference and\ntraining performance of your models over time. This logging is performed ",(0,t.jsx)(i.strong,{children:"entirely on your\nmachine"}),". Monitoring and logging are crucial to ensure your models are performing as expected and\nto identify any potential issues early on. All logs are written automatically after every\ninference and training session in the ",(0,t.jsx)(i.code,{children:"artifex_logs/"})," folder in your current working directory."]}),"\n",(0,t.jsxs)(i.p,{children:["Logs include ",(0,t.jsx)(i.strong,{children:"operation-level metrics"})," (e.g., inference duration, CPU & RAM usage, training\nloss, etc.), ",(0,t.jsx)(i.strong,{children:"daily aggregated metrics"})," and any ",(0,t.jsx)(i.strong,{children:"errors encountered"})," during inference or\ntraining. Additionally, ",(0,t.jsx)(i.strong,{children:"warnings for potential issues"})," (e.g., high inference duration, low\nconfidence scores, high training loss, etc.) are logged in a separate warnings log file for easier\nidentification and troubleshooting."]}),"\n",(0,t.jsx)(i.p,{children:"Below is a list of all the metrics and warnings logged by Artifex:"}),"\n",(0,t.jsx)(i.h2,{id:"inference-logs",children:"Inference logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"timestamp"}),"\n",(0,t.jsx)(i.li,{children:"model used"}),"\n",(0,t.jsx)(i.li,{children:"inference duration"}),"\n",(0,t.jsx)(i.li,{children:"CPU & RAM usage"}),"\n",(0,t.jsx)(i.li,{children:"input token count"}),"\n",(0,t.jsx)(i.li,{children:"inference input & output"}),"\n",(0,t.jsx)(i.li,{children:"inference errors (if any)"}),"\n",(0,t.jsx)(i.li,{children:"Daily total inferences count"}),"\n",(0,t.jsx)(i.li,{children:"Daily total & average input token count"}),"\n",(0,t.jsx)(i.li,{children:"Daily total & average inference duration"}),"\n",(0,t.jsx)(i.li,{children:"Daily average RAM & CPU usage"}),"\n",(0,t.jsx)(i.li,{children:"Daily average confidence score"}),"\n",(0,t.jsx)(i.li,{children:"Daily model usage breakdown"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"training-logs",children:"Training logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"timestamp"}),"\n",(0,t.jsx)(i.li,{children:"model trained"}),"\n",(0,t.jsx)(i.li,{children:"training duration"}),"\n",(0,t.jsx)(i.li,{children:"CPU & RAM usage"}),"\n",(0,t.jsx)(i.li,{children:"training instructions & parameters"}),"\n",(0,t.jsx)(i.li,{children:"training results (loss, samples/second, steps/second)"}),"\n",(0,t.jsx)(i.li,{children:"training errors (if any)"}),"\n",(0,t.jsx)(i.li,{children:"Daily total trainings count"}),"\n",(0,t.jsx)(i.li,{children:"Daily average training duration"}),"\n",(0,t.jsx)(i.li,{children:"Daily average CPU & RAM usage"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"warning-logs",children:"Warning logs:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Warning for low confidence scores during inference"}),"\n",(0,t.jsx)(i.li,{children:"Warning for slow inference (> 5 seconds)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for high inference input token count (> 2048 tokens)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for short inference input text (< 10 characters)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for null inference output"}),"\n",(0,t.jsx)(i.li,{children:"Warning for high training loss (> 1.0)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for slow training (> 5 minutes)"}),"\n",(0,t.jsx)(i.li,{children:"Warning for low training throughput (< 1 sample/second)"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"centralized-logging-monitoring-and-alerting",children:"Centralized logging, monitoring and alerting"}),"\n",(0,t.jsx)(i.p,{children:"Want to view, search, and correlate logs from all your models in one place, to easily debug production issues and understand system behavior over time, without digging through individual log files? Simply do the following:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:["Create a free account ",(0,t.jsx)(a.A,{to:l.Ko,children:"on the Tanaos platform"})]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:["Create an API key from ",(0,t.jsx)(a.A,{to:l.fO,children:"your profile page"})]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsx)(i.p,{children:"Instantiate Artifex with your API key:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'from artifex import Artifex\n\nguardrail = Artifex(\n    api_key="<YOUR_API_KEY_HERE>"\n).guardrail\n'})}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["\n",(0,t.jsxs)(i.p,{children:["Use Artifex as usual. All logs will be sent to your account on our platform. You can view them\non ",(0,t.jsx)(a.A,{to:l.hm,children:"your traces page"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)("img",{src:"https://raw.githubusercontent.com/tanaos/artifex/master/assets/platform-inference-logs.png",width:"600px",alt:"Artifex \u2013 Centralized logging, monitoring and alerting for Small Language Models"}),"\n",(0,t.jsx)(i.h2,{id:"opting-out-of-logging",children:"Opting out of logging"}),"\n",(0,t.jsxs)(i.p,{children:["You can opt-out of logging by passing the ",(0,t.jsx)(i.code,{children:"disable_logging=True"})," flag when training or performing\ninference with any model:"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'from artifex import Artifex\n\nguardrail = Artifex().guardrail\nprint(guardrail("How do I make a bomb?", disable_logging=True))\n'})})]})}function h(n={}){const{wrapper:i}={...(0,o.R)(),...n.components};return i?(0,t.jsx)(i,{...n,children:(0,t.jsx)(u,{...n})}):u(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>a,x:()=>l});var r=e(6540);const t={},o=r.createContext(t);function a(n){const i=r.useContext(o);return r.useMemo((function(){return"function"==typeof n?n(i):{...i,...n}}),[i,n])}function l(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:a(n.components),r.createElement(o.Provider,{value:i},n.children)}}}]);